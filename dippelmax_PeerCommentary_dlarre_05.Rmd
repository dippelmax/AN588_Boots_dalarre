---
title: "Untitled"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


##Homework 05

#[1] Using the “KamilarAndCooperData.csv” dataset, run a linear regression looking at log(HomeRange_km2) in relation to log(Body_mass_female_mean) and report your β coeffiecients (slope and intercept).

```{r}

library(curl)
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)
names(d)
## This loads the data

```

```{r}
library(lmodel2) ## Load the Model II regression package

hr <- log(d$HomeRange_km2)
bmfm <- log(d$Body_mass_female_mean)

f <- cbind(d, hr, bmfm)

m <- lmodel2(hr ~ bmfm, data = f, range.y = "interval", range.x = "relative", 
    nperm = 1000)
m

b1 <- m$regression.results$Slope[1]
b1 ##Slope

b0 <- m$regression.results$Intercept[1]
b0 ##Intercept

```

# This is not the way I did it. The function I used was just lm() and you can log the() results within the function. I am not sure what log model II is but I got the same intercepts as you did so it looks like it works. 


#[2] Then, use bootstrapping to sample from your data 1000 times with replacement, each time fitting the same model and calculating the same coefficients. This generates a sampling distribution for each β coefficient.

Estimate the standard error for each of your β coefficients as the standard deviation of the sampling distribution from your bootstrap and determine the 95% CI for each of your β coefficients based on the appropriate quantiles from your sampling distribution.

How does the former compare to the SE estimated from your entire dataset using the formula for standard error implemented in lm()?

How does the latter compare to the 95% CI estimated from your entire dataset?

```{r}
s1 <- NULL
s2 <- NULL
for (i in 1:1000) {
    s1[[i]] <- sample(f$hr, size = 200, replace = TRUE)
    s2[[i]] <- sample(f$bmfm, size = 200, replace = TRUE)
}
## First, I sample 1000 times from each variable, with a sample size of 100


mm <- NULL
beta1 <- NULL
beta0 <- NULL
for (i in 1:1000) {
  mm[[i]] <- lmodel2(s1[[i]]~s2[[i]],data = f, range.y = "interval", range.x = "relative")
  beta1[i] <- mm[[i]]$regression.results$Slope[1]
  beta0[i] <- mm[[i]]$regression.results$Intercept[1]
}
## Then I run a for loop for doing the model 2 regression of each sample. I get the warning that "No permutation test will be performed" on each regression because if I add a permutation number the loop takes forever to run. I also get all the slopes and intercepts stored as vectors in the variables beta1 and beta0.

```

# It is possible to combine those two and use the samples within the function to make the beta outputs

# that "No permutation test will be performed" error is totally weird

# I am not sure what the variable s1[[i]] is doing. I would try to just use regular variables like s1 or s2 instead of adding i with brackets to everything

```{r}

mm[[1]]
mm[[1000]]

mmi <- NULL
for (i in 1:1000) {
  mmi[[i]] <- lm(s1[[i]]~s2[[i]])
}
mmi[[1]]
mmi[[1000]]
## Here I do a test to see if there is a notable difference between using linear model 1 or 2, and the results are pretty much the same in both of them.

```



```{r}

sd0 <- sd(beta0) ## Calculates the estimation of the standard error for β0 coefficient as the standard deviation of its sampling distribution 
sd1 <- sd(beta1) ## Calculates the estimation of the standard error for β1 coefficient as the standard deviation of its sampling distribution 


## Next I calculate the SE and 95% CIs of the coefficients using the whole dataset for comparing them to the ones obtained by bootstrapping, and I collect all the data in a data frame called "table" to have an easy way to compare.

mi <- lm(hr ~ bmfm)
u <- coef(summary(mi))
u <- data.frame(unlist(u))
colnames(u) <- c("Estimate", "SE", "t", "p") ## This contains the data about the coefficients calculated with lm()
u
ci <- confint(mi, level = 0.95)  # This calculates the CIs for the slope (β1) and the intercept (β0)

t <- data.frame(Bootstrapping_SE = c(sd0, sd1), Bootstrapping_2.5 = c(quantile(beta0, 0.025),quantile(beta1, 0.025)), Bootstrapping_97.5 = c(quantile(beta0, 0.975),quantile(beta1, 0.975))) ## This creates a data frame with all the data obtained by bootstrapping

table <- cbind(u[,1:2],t,ci) ## This gathers the different data frames into a single one
table

## We can see that the standard errors aren't the same but are relatively close. The ones calculated by bootstrapping are higher. 
## However, the CIs are totally different. I don't know if I have done something wrong calculating them or if this result is normal.

```

# All of the values look good to me! seems like despite the premutations thing your code works and you get good values for the SE and such


